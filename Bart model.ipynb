{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install -Uq git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "id": "Pmao8JpRR_Kd",
        "outputId": "8ebc344f-ff80-4662-b431-1c77b966b5bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load BERT models and tokenizers\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "model_correct = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define the transcript\n",
        "\n",
        "meeting_transcript = \"\"\"\n",
        "\n",
        "J: Good morning, everyone! Let's get started. Today's meeting is about brainstorming new marketing ideas for our upcoming product launch. Any suggestions?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "S: I think we should leverage social media platforms to reach a wider audience. We can create engaging content and run targeted ad campaigns.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "M: That's a great idea, Sarah. We should also consider collaborating with influencers in our industry to promote our product.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "L: I agree. Influencer marketing has been proven to be effective. We can identify key influencers and reach out to them for partnerships.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "J: Excellent suggestions so far. How about exploring offline marketing channels as well? We could organize local events or sponsor relevant community gatherings.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "S: That's a good point, John. Local events can help us establish a strong presence in the community and create brand awareness.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "M: Another idea could be to offer referral incentives to our existing customers. They can spread the word about our product and earn rewards in return.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "L: I like that idea, Mark. Referral programs can generate a lot of word-of-mouth marketing and bring in new customers.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "J: Great ideas, everyone! Let's summarize our action items. Sarah, you will lead the social media marketing efforts. Mark, please research potential influencers for partnerships. Lisa, explore offline marketing opportunities such as local events. And I'll take charge of setting up the referral program.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "S: Sounds good, John. I'll start working on the social media strategy right away.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "M: I'll begin researching influencers and compile a list for our review.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "L: I'll look into local events and see what options are available for us.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "J: Perfect. Let's reconvene next week with our progress reports. Thanks, everyone!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "--------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "End of Meeting Transcript\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tokenize and encode the transcript\n",
        "\n",
        "input_ids = tokenizer.encode(transcript, add_special_tokens=True, truncation=True, max_length=512, padding='max_length', return_tensors='pt')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Perform correction\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model_correct(input_ids)\n",
        "\n",
        "    predicted_label = torch.argmax(outputs.logits)\n",
        "\n",
        "    corrected_transcript = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
        "\n",
        "# Generate summary\n",
        "\n",
        "summary_input = tokenizer.prepare_seq2seq_batch([corrected_transcript], truncation=True, padding='longest', return_tensors='pt')\n",
        "\n",
        "summary_ids = model.generate(input_ids=summary_input['input_ids'], num_beams=6, max_length=100, early_stopping=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Print the corrected transcript and summary\n",
        "\n",
        "print(\"Corrected Transcript:\", corrected_transcript)\n",
        "\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "id": "UE5iW4x2SCyu",
        "outputId": "d9bd770f-2676-4185-c20a-3f10f0a3c43a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3766: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected Transcript: meeting transcript - team brainstorming session j : good morning, everyone! let's get started. today's meeting is about brainstorming new marketing ideas for our upcoming product launch. any suggestions? s : i think we should leverage social media platforms to reach a wider audience. we can create engaging content and run targeted ad campaigns. m : that's a great idea, sarah. we should also consider collaborating with influencers in our industry to promote our product. l : i agree. influencer marketing has been proven to be effective. we can identify key influencers and reach out to them for partnerships. j : excellent suggestions so far. how about exploring offline marketing channels as well? we could organize local events or sponsor relevant community gatherings. s : that's a good point, john. local events can help us establish a strong presence in the community and create brand awareness. m : another idea could be to offer referral incentives to our existing customers. they can spread the word about our product and earn rewards in return. l : i like that idea, mark. referral programs can generate a lot of word - of - mouth marketing and bring in new customers. j : great ideas, everyone! let's summarize our action items. sarah, you will lead the social media marketing efforts. mark, please research potential influencers for partnerships. lisa, explore offline marketing opportunities such as local events. and i'll take charge of setting up the referral program. s : sounds good, john. i'll start working on the social media strategy right away. m : i'll begin researching influencers and compile a list for our review. l : i'll look into local events and see what options are available for us. j : perfect. let's reconvene next week with our progress reports. thanks, everyone! - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - end of meeting transcript\n",
            "Summary: meeting transcript - team brainstorming session j : good morning, everyone! let's get started. today's meeting is about brainstorming new marketing ideas for our upcoming product launch. any suggestions? s : i think we should leverage social media platforms to reach a wider audience. we can create engaging content and run targeted ad campaigns. we should also consider collaborating with influencers in our industry to promote our product. l : i agree. influencer marketing has been proven to be effective.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary: meeting transcript - team brainstorming session j : good morning, everyone! let's get started. today's meeting is about brainstorming new marketing ideas for our upcoming product launch. any suggestions? s : i think we should leverage social media platforms to reach a wider audience. we can create engaging content and run targeted ad campaigns. we should also consider collaborating with influencers in our industry to promote our product. l : i agree. influencer marketing has been proven to be effective.\n"
      ],
      "metadata": {
        "id": "EXKYYnMifHXp"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}