{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "id": "cz8ypBdDNZmL",
        "outputId": "35188475-00e8-4844-8a0f-8deae156d68b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Generated Summary:\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Generated Summary:\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">the meeting is about brainstorming new marketing ideas for our upcoming product launch. we should also consider \n",
              "collaborating with influencers in our industry to promote our product.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "the meeting is about brainstorming new marketing ideas for our upcoming product launch. we should also consider \n",
              "collaborating with influencers in our industry to promote our product.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import T5Tokenizer,T5ForConditionalGeneration\n",
        "\n",
        "# Load the T5 tokenizer\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "def predict_summary(model, input_text):\n",
        "    # Tokenize the input text\n",
        "    input_tokens = tokenizer.encode(\"summarize: \" + input_text,\n",
        "                                     max_length=1000,\n",
        "                                     truncation=True,\n",
        "                                     return_tensors=\"pt\")\n",
        "\n",
        "    input_tokens = input_tokens.to(device)\n",
        "\n",
        "    # Generate the summary\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(input_tokens,\n",
        "                                num_beams=4,       # Number of beams for beam search\n",
        "                                min_length=30,     # Minimum length of the generated summary\n",
        "                                max_length=150,    # Maximum length of the generated summary\n",
        "                                early_stopping=True,\n",
        "                                no_repeat_ngram_size=2)\n",
        "\n",
        "    # Decode the generated summary back to text\n",
        "    summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Assuming you have a variable named 'model' containing the trained T5 model\n",
        "\n",
        "# Sample input meeting transcript\n",
        "meeting_transcript = \"\"\"\n",
        "J: Good morning, everyone! Let's get started. Today's meeting is about brainstorming new marketing ideas for our upcoming product launch. Any suggestions?\n",
        "\n",
        "S: I think we should leverage social media platforms to reach a wider audience. We can create engaging content and run targeted ad campaigns.\n",
        "\n",
        "M: That's a great idea, Sarah. We should also consider collaborating with influencers in our industry to promote our product.\n",
        "\n",
        "L: I agree. Influencer marketing has been proven to be effective. We can identify key influencers and reach out to them for partnerships.\n",
        "\n",
        "J: Excellent suggestions so far. How about exploring offline marketing channels as well? We could organize local events or sponsor relevant community gatherings.\n",
        "\n",
        "S: That's a good point, John. Local events can help us establish a strong presence in the community and create brand awareness.\n",
        "\n",
        "M: Another idea could be to offer referral incentives to our existing customers. They can spread the word about our product and earn rewards in return.\n",
        "\n",
        "L: I like that idea, Mark. Referral programs can generate a lot of word-of-mouth marketing and bring in new customers.\n",
        "\n",
        "J: Great ideas, everyone! Let's summarize our action items. Sarah, you will lead the social media marketing efforts. Mark, please research potential influencers for partnerships. Lisa, explore offline marketing opportunities such as local events. And I'll take charge of setting up the referral program.\n",
        "\n",
        "S: Sounds good, John. I'll start working on the social media strategy right away.\n",
        "\n",
        "M: I'll begin researching influencers and compile a list for our review.\n",
        "\n",
        "L: I'll look into local events and see what options are available for us.\n",
        "\n",
        "J: Perfect. Let's reconvene next week with our progress reports. Thanks, everyone!\n",
        "\n",
        "--------------------------------------\n",
        "\n",
        "End of Meeting Transcript\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Predict the summary\n",
        "predicted_summary = predict_summary(model, meeting_transcript)\n",
        "\n",
        "print(\"Generated Summary:\")\n",
        "print(predicted_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAaBMvQWY8Qx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
